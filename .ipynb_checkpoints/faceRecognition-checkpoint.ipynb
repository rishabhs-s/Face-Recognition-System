{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2.cvtColor() method is used to convert an image from one color space to another. There are more than 150 color-space conversion methods available in OpenCV. <br><br>\n",
    "Haar Cascade is a machine learning object detection algorithm used to identify objects in an image or video.It is a machine learning based approach where a cascade function is trained from a lot of positive and negative images. It is then used to detect objects in other images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step-1) Import cv2 and numpy and also use the CascadeClassifier function of OpenCV to point to the location where we have stored the XML file<br><br>\n",
    "Step-2) Generally the images that we see are in the form of RGB channel(Red, Green, Blue). So, when OpenCV reads the RGB image, it usually stores the image in BGR (Blue, Green, Red) channel. For the purposes of image recognition, we need to convert this BGR channel to gray channel. The reason for this is gray channel is easy to process and is computationally less intensive as it contains only 1-channel of black-white.<br><br>\n",
    "So we convert it to gray-scale<br><br>\n",
    "Step-3) detectMultiScale() will help us to find the features/locations of the new image. The way it does is, it will use all the features from the face_classifier object to detect the features of the new image. It will now try to locate the exact features in our face.It has some parameters scaleFactors,minNeighbors<br><br>\n",
    "scaleFactor — Parameter specifying how much the image size is reduced at each image scale<br><br>\n",
    "minNeighbors — Parameter specifying how many neighbors each candidate rectangle should have to retain it. This parameter will affect the quality of the detected faces.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facedetection(test_img):\n",
    "    gray_img=cv2.cvtColor(test_img,cv2.COLOR_BGR2GRAY)#BGR2GRAY converts image to grayscale to avoid unnecessary functionalities\n",
    "    face_haar_cascade=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    faces=face_haar_cascade.detectMultiScale(gray_img,scaleFactor=1.32,minNeighbors=5)#returns the rectangles where face is detected in particular\n",
    "    return faces,gray_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OS.walk() generate the file names in a directory tree by walking the tree either top-down or bottom-up. For each directory in the tree rooted at directory top (including top itself), it yields a 3-tuple (dirpath, dirnames, filenames).<br><br>\n",
    "\n",
    "root : Prints out directories only from what you specified.<br>\n",
    "dirs : Prints out sub-directories from root.<br>\n",
    "files : Prints out all files from root and directories.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_for_training_data(directory):\n",
    "    faces=[]\n",
    "    faceid=[] #labels corresponding to faces\n",
    "    \n",
    "    for path,subdirnames,filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            if filename.startswith(\".\"):\n",
    "                print(\"Skipping this system file\")\n",
    "                continue\n",
    "            id=os.path.basename(path)\n",
    "            print(\"id: \",id)\n",
    "            img_path=os.path.join(path,filename)\n",
    "            print(\"img_path: \",img_path)\n",
    "            test_img=cv2.imread(img_path)\n",
    "            if test_img is None:\n",
    "                print(\"image not loaded properly\")\n",
    "                continue\n",
    "            faces_rect,gray_img=facedetection(test_img)\n",
    "            if len(faces_rect)!=1:#when multiple faces are present\n",
    "                continue\n",
    "            (x,y,w,h)=faces_rect[0]\n",
    "            roi_gray=gray_img[y:y+w,x:x+h]#roi-reigon of interest so giving only face to the classifer\n",
    "            faces.append(roi_gray)\n",
    "            faceid.append(int(id))\n",
    "    return faces,faceid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LBPH- Local Binary Patterns Histograms\n",
    "<img src=\"img.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_classifier(faces,faceid):\n",
    "    face_recognizer=cv2.face.LBPHFaceRecognizer_create()\n",
    "    face_recognizer.train(faces,np.array(faceid))\n",
    "    return face_recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rect(test_img,face):\n",
    "    (x,y,w,h)=face\n",
    "    cv2.rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_Text(test_img,text,x,y):\n",
    "    cv2.putText(test_img,text,(x,y),cv2.FONT_HERSHEY_DUPLEX,2,(255,0,0),4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
